---
title: "Demo-3"
subtitle: "Variograms"
author: "Jeffrey Yarus"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: 
    highlight: tango
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 6
  html_document: default
  word_document: 
    toc: yes
    toc_depth: '6'
  always_allow_html: yes
editor_options: 
  chunk_output_type: console
---

# Demo Summary

In this demo, the objective is to become familiar with how to construct both omnidirectional and directional variograms.   

Here, the code begins as usual by reading in the data set, creating the assignment variables, identifying outliers, and removing the outliers. We are now ready to create variograms.  **Please be sure to read through the text I have included before each code chunk. .**  

First, run the script chunk by chunk.  After the initial data frames are calculated, I create a data base called db as we did in the previous demo. This data base looks a lot like the data frame df and, as you recall, it contains the outliers.  You will see that I correct for the outliers and create a data base without the outliers called **db_noout.db**.  You will need to walk through the chunks one-at-a-time and change **db** in each chunk to **db_noout.db** in order to see the impact without the outlier. Take your time and feel free to swap the data bases back and forth to see the impact with the outlier and without. 

# Terminology, packages, and key functions from this Demo

1. **Variogram Map** :  A Variogram map is a graph that that displays the change in variance in all directions from the origin located at its center. It is actually a polar plot and requires a "lot" of data to produce, so data sets that are sparse will not be very useful.  Grid data, like satellite images, gravity, magnetics, geophysical surveys etc. produce excellent variogram maps.   

# Loading Packages

Run the code chunk below...

```{r include = FALSE}
library(corrplot)
library(PerformanceAnalytics)
library(tidyverse)
library(fastDummies)
library(magrittr)
library(GGally)
library(ggplot2)
library(RColorBrewer)
library(knitr)
library(ggpubr)
library(gstlearn)
library(here)
```


```{r, eval=FALSE}
setwd('/mnt/vstor/CSE_MSE_RXF131/cradle-members/sdle/jmy41/GIT/jmy-research/topics/RPS_N58')

getwd()
```


As in the previous demos, we:

- Read in our data
- Create the tibble
- Ensure our categorical variables are designated as factors
- Create a backup data frame
- Remove the unnecessary variables from the tibble
- Create our assigned symbolic names
- Identify the outliers. all of this is being done in one code chunk.

Run the chunk below...

```{r }
file.name <- "../../data/WT-2D-all-outlier.csv"
df <- read_csv(file.name)
df %<>%
  mutate(across(matches("N_|L_"), factor))
head(df, n = 20)

# Creating a duplicate tibble for later use, but eliminate unnecessary variables

df2 <- df %>%
  dplyr::select(L_3_FACIES:P_Top_ft)

# Creating Symbolic Inputs

xlon <- "C_X_ft"
ylat <- "C_Y_ft"
out_analysis <- "Raw (outlier analysis performed on raw data)"
property <-
  "P_PHI_pct" # The property you are selecting for analysis

## Data Analytics - Managing outliers

df <-
  df %>%
  mutate(
    iqr_val = IQR(!!sym(property)),
    # calculates the IQR value
    iqr_val_adj = ((iqr_val) * 1.5),
    third_q = quantile(!!sym(property), prob = 0.75, na.rm = TRUE),
    first_q = quantile(!!sym(property), prob = .25, na.rm = TRUE),
    # Creating a column of True and False, True = an outlier, False = not an
    #outlier
    outlier =
      (!!sym(property)) > (third_q + iqr_val_adj) |
      (!!sym(property) < (first_q - iqr_val_adj))
  ) 
df
```
# Create a database from the dataframe and select properties for analysis

Run the chunk below...

```{r warning = FALSE, message = FALSE}
# Remove the first variable
df1 = df %>% dplyr::select(-F_Top)

# creating a database with the outlier from the Data Frame
db = Db_fromTL(df1)

# Define the different variables
err = db$setLocators(c(xlon, ylat), ELoc_X())
err = db$setLocator(property, ELoc_Z())

db
```


```{r}
# Creating databases with no outliers
# Remove the first variable
df1 = df %>% dplyr::select(-F_Top) %>% filter(outlier == FALSE)

# creating a database with the outlier from the Data Frame
db_noout.db = Db_fromTL(df1)

# Define the different variables
err = db_noout.db$setLocators(c(xlon, ylat), ELoc_X())
err = db_noout.db$setLocator(property, ELoc_Z())

db_noout.db 
```

# Create the Basemap without the outlier

In this code chunk the basemap without the outlier is reproduced.

**(note, you will need to replace the database db_noout.db if you want to see the impact of the outlier)**

Run the chunk below...

```{r}
p = plot.init(asp=1)
p = p + plot.symbol(db, nameColor=property)
p = p + plot.decoration(title="Display of Grid Nodes")
plot.end(p)
```


```{r, warning=FALSE}
p = plot.init(asp=1)
p = p + plot.symbol(
  # db,                      # Comment out to remove outlier
  db_noout.db,               # Uncomment to remove outlier
  nameColor = property,
  pch = 19,
  cex = 0.5, 
  flagLegend = TRUE)
p = p + plot.geometry(xlim = c(-20000, 50000), ylim = c(0, 40000))
p = p + plot.decoration(title=paste("Basemap of", property, "with No Outlier"), xlab = "X (UTM)", ylab = "Y (UTM)")
plot.end(p)
```

# Outliers

The code chunck below displays the histogram from the selected variable.  Note the outlier on the far right of the histogram

Run the chunk below...

```{r message = FALSE, warning = FALSE}
hist1 <- df %>%
  filter(outlier == FALSE) %>%
  ggplot(aes(x = !!sym(property))) +
  geom_histogram(           #   Plots the histogram
    aes(y = ..density..),
    fill = "red",
    color = "white",
    bins = 31,             #   Smooths out the histogram and ensures center bin
    alpha = 0.6            #   Provides transparency to histogram see CDF better
  ) +
  geom_density(color = "black", size = 1) +     #   Plots the Density Curve
  stat_ecdf(
    aes(y = ..y..),
    color = "blue",
    size = 1,
    linetype = "dashed"
  ) +                      #   Plots the CPDF overlay
  ggtitle(sprintf("Fig 1b     %s WT Data", property)) +
  xlab(property) +
  ylab("Density / Cumulative Probability")

hist1
```

Note the "Density" curve in black is a "Probability Distribution Function". It shows a smoothed, continuous estimate of the data distribution â€” helpful for spotting skewness, multi-modality, or how normal (Gaussian) the data are. The blue curve is the "Cumulative Probability distribution function" or CPDF.  

# Construction of the Variograms

The code chunks below calculates and plots the variograms. Initially, they do not correct for outliers.  Replace the database (db) with the database that removes the outliers (db_noout.db). Observe the impact of the outlier. 

## The Omnidirectional Experimental Semivariogram

Look what happens in the variogram when you do not remove the outlier!
To see the impact, be sure the data base is, "db".  To see the impact without the outlier, change the data base name to, "db_noout". 

Run the code chunk below...

```{r, warning = FALSE}
varioparam <- VarioParam_createOmniDirection(nlag = 10, dlag=2000)
vario_omni <- Vario_computeFromDb(varioparam, db_noout.db)

p = plot.init()
p = p + plot.vario(vario_omni, drawPlabel = TRUE)
p = p + plot.decoration(title = paste(property, "Experimental Ominidirectional Variogram"), 
                        xlab = "Lag distance", 
                        ylab = expression(paste("Variance (", gamma, "(h))", sep="")))
plot.end(p)
```

# Directional Variograms

## Directional Experimental Semi- Variograms

The same process is followed for directional variograms.  Note, however, that the number of arguments increases and we include the multiple directions we want to assess.  When entering the directions, begin with the most northerly direction.  **If you enter only 2 directions, like c(90, 0), then gstlearn assumes you explicitly know the maximum and minimum directions of continuity.** If you enter 3 or more directions, like, C(90, 45, 0) or c(90, 60, 30, 0), gstlearn will automatically calculate the directions of continuity if you are using the function "vario_calc()" along with "model.auto()."  This is very handy and makes variogram modeling much easier.  

In the code chunk below, we calculate the directional variograms for 2 directions, 3 directions, and 4 directions.  .

Run the chunk below...

```{r, warning = FALSE}
#This time to calculate multiple specific directions , such as 0, 90 degrees
varioparam <- VarioParam_createMultiple(ndir = 2, nlag = 10, dlag=2000)
data.2dir.vario <- Vario_computeFromDb(varioparam, db_noout.db)

p = plot.init()
p = p + plot.vario(data.2dir.vario, drawPlabel = TRUE, flagLegend=TRUE)
p = p + plot.decoration(title = paste(property, "Experimental 2 Directional Variogram"),
                        xlab = "Lag distance",
                        ylab = expression(paste("Variance (", gamma, "(h))", sep = "")))
plot.end(p)

#This time to calculate multiple specific directions , such as 0, 45, 90 and 135 degrees
varioparam <- VarioParam_createMultiple(ndir = 4, nlag = 10, dlag=2000)
data.4dir.vario <- Vario_computeFromDb(varioparam, db_noout.db)

p = plot.init()
p = p + plot.vario(data.4dir.vario, drawPlabel = TRUE, flagLegend=TRUE)
p = p + plot.decoration(title = paste(property, "Experimental 4 Directional Variogram"),
                        xlab = "Lag distance",
                        ylab = expression(paste("Variance (", gamma, "(h))", sep = "")))
plot.end(p)
```

Recall that each point represents the average squared difference value for each lag.  The small numbers printed above each point is the number of pair-points that went into that lag calculation.  

**End of Demo#3a-2025-SM**